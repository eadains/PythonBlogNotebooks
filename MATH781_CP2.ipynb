{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We can use Newton's Method to find the roots of differentiable functions. The approach is to iterate from some starting guess of what the root is using the following formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n",
    "\\end{equation*}\n",
    "\n",
    "where we let $x_0$ be our starting guess.\n",
    "\n",
    "Theoretically, if $x_0$ is sufficiently close to the true root, say $r$ of the function under study, then $x_n \\to r$ as $n \\to \\infty$. However, in practice establishing this initial guess is difficult, and numerical issues may cause this to fail. Here, I will explore this process and its behavior with an example function across a variety of parameters.\n",
    "\n",
    "# Mathematical Formulation\n",
    "\n",
    "In psuedo-code the algorithm we will use is this:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Input:} &\\quad x_0, f(x), f'(x), N, \\epsilon_1, \\epsilon_2 \\\\\n",
    "\\text{Output:} &\\quad \\alpha, flag \\\\\n",
    "\\text{1.}& \\quad flag = True \\\\\n",
    "\\text{2.}& \\quad \\text{For} \\; n = 1:N \\\\\n",
    "&\\quad \\text{(a)} \\quad f_x = f(x_0), \\; df_x = f'(x_0) \\\\\n",
    "&\\quad \\text{(b)} \\quad \\text{if} \\; |df_x| \\leq \\epsilon_M \\; \\text{then} \\; flag = False \\; \\text{then break} \\\\\n",
    "&\\quad \\text{(c)} \\quad \\text{if} \\; |f_x| \\leq \\epsilon_1 \\; \\text{then} \\; \\alpha = x_0, \\; \\text{then break} \\\\\n",
    "&\\quad \\text{(d)} \\quad \\text{if} \\; n \\gt 0 \\: \\text{and} \\; |x_1 - x_0| \\leq \\epsilon_2 \\; \\text{then} \\; \\alpha = x_0, \\;\\text{then break} \\\\\n",
    "&\\quad \\text{(e)} \\quad x_1 = x_0, \\; x_0 = x_0 - \\frac{f_x}{df_x}\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\epsilon_M$ denotes the machine epsilon. Step (b) checks to see if the current derivative evaluation is close enough to zero that our step size would be zero. Step (c) checks to see if evaluating the function at the current guess is sufficiently close to zero, in which case we have found a root so we can stop. Step (d) checks to see if we are still making progress between iterations. If our last guess and our current guess are sufficiently close together, then we aren't making any better guess, so we can stop iterating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(x_0, f, df, N, eps_1, eps_2):\n",
    "    flag = True\n",
    "    x_1 = x_0\n",
    "    for n in range(N):\n",
    "        f_x = f(x_0)\n",
    "        df_x = df(x_0)\n",
    "        if abs(df_x) <= 10e-16:\n",
    "            flag = False\n",
    "            return flag\n",
    "        elif abs(f_x) <= eps_1:\n",
    "            return x_0\n",
    "        elif (n > 0) and (abs(x_1 - x_0) <= eps_2):\n",
    "            return x_0\n",
    "        else:\n",
    "            x_1 = x_0\n",
    "            x_0 = x_0 - f_x / df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, B):\n",
    "    return x + np.exp(-B * x**2) * np.cos(x)\n",
    "\n",
    "def df(x, B):\n",
    "    return -np.exp(-B * x**2) * np.sin(x) - 2 * B * x * np.exp(-B * x**2) * np.cos(x) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bs = [1, 5, 10, 25, 50]\n",
    "x_0s = [-5, -1, 0, 1, 5]\n",
    "results = {}\n",
    "\n",
    "for B in Bs:\n",
    "    x_results = {}\n",
    "    for x_0 in x_0s:\n",
    "        root = newton(x_0, lambda x: f(x, B), lambda x: df(x, B), 1000, 10e-15, 10e-15)\n",
    "        x_results[x_0] = root\n",
    "    results[B] = x_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {-5: -0.5884017765009963,\n",
       "  -1: -0.5884017765009963,\n",
       "  0: -0.5884017765009963,\n",
       "  1: -0.5884017765009962,\n",
       "  5: -0.5884017765009963},\n",
       " 5: {-5: -0.4049115482093092,\n",
       "  -1: -0.4049115482093092,\n",
       "  0: -0.4049115482093092,\n",
       "  1: -0.4049115482093092,\n",
       "  5: -0.4049115482093092},\n",
       " 10: {-5: None, -1: None, 0: None, 1: None, 5: None},\n",
       " 25: {-5: None, -1: None, 0: None, 1: None, 5: None},\n",
       " 50: {-5: None, -1: None, 0: None, 1: None, 5: None}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| B | $x_0$ | Root |\n",
    "| - | ----- | ---- |\n",
    "| $1$ | $-5$ | $-0.5884017765009963$ |\n",
    "| $1$ | $-1$ | $-0.5884017765009963$ |\n",
    "| $1$ | $0$ | $-0.5884017765009963$ |\n",
    "| $1$ | $1$ | $-0.5884017765009962$ |\n",
    "| $1$ | $5$ | $-0.5884017765009963$ |\n",
    "| $5$ | $-5$ | $-0.4049115482093092$ |\n",
    "| $5$ | $-1$ | $-0.4049115482093092$ |\n",
    "| $5$ | $0$ | $-0.4049115482093092$ |\n",
    "| $5$ | $1$ | $-0.4049115482093092$ |\n",
    "| $5$ | $5$ | $-0.4049115482093092$ |\n",
    "| $10, 25, 50$ | $-5, -1, 0, 1, 5$ | N/A |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from these results that for $B = 1, 5$ and any intial starting value, Newton's Method converges to the same root to a very high degree of precision. However, for values of $B \\ge 10$ the algorithm does not converge for any starting value. This is because the algorithm gets \"stuck\" oscillating between $x_0 = -1$ and $x_0 = 0$. This is because $f'(x) \\approx 1$ at those points. So, at each iteration if $x_n = 1$ then $x_{n+1} = 1 - 1 = 0$ and when $x_n = 0$ then $x_{n+1} = 0 - 1 = -1$. This doesn't happen for smaller values of $B$ because then the derivative at $x = -1$ is less close to $1$, so the next point is not exactly 0.\n",
    "\n",
    "However, even for larger values of $B$, there are ranges of starting values that do result in convergence. For example, when $B=10$ and $x_0 = 0.8$ we get convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3264020100974987"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newton(0.80, lambda x: f(x, 10), lambda x: df(x, 10), 1000, 10e-15, 10e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, once again, if we increase $B$ further, it fails to converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton(0.80, lambda x: f(x, 25), lambda x: df(x, 25), 1000, 10e-15, 10e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, we can again find a starting value that allows for convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2374362439062778"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newton(0.10, lambda x: f(x, 25), lambda x: df(x, 25), 1000, 10e-15, 10e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cases with the right starting values, the algorithm doesn't get \"trapped\" in the loop between values of $1$ and $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We can see from these results that when the function and starting value are appropriate, Newton's method converges consistently and accurately to the roots of a function. However, we can also see that the method can be very sensitive to starting values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
